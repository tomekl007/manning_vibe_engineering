# Context is Currency: Precision and High‑Signal Prompts

```
An LLM can’t read minds - it feeds on the crumbs you drop. The richer, tighter, and more surgical that context, the sharper the output. This chapter shows you how to slice big features into bite‑size tasks, tag logs and stack traces so the model sees just the right noise, and run a “plan → execute → debug” loop where the AI drafts, fixes, and explains in one continuous flow. Master context engineering and the model stops guessing - and starts delivering.

Check the Vibe
If your prompt says “it’s broken” instead of pasting the exact stack trace, you’re starving the bot and expecting good results in return.

Street Rule
Specific beats terrific. High‑resolution context = high‑precision code.

Move to Make
Split reasoning over the feature phase and writing code phase - like all good engineers are taught to do. The more time you spend on spec, the more predictable results from AI Agent can be expected. 
```

## Prompts